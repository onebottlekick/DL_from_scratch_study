{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter4 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 데이터에서 학습한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 데이터 주도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deep learning : end to end machine learning  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수(loss function): 신경망 학습에 사용하는 지표로, 일반적으로 오차제곱합과 교차 엔트로피 오차를 사용한다.  \n",
    "(낮을 수록 좋음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 오차제곱합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SSE(sum of squares for error) = E = 1/2(sum((y_pred - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_squares_error(y_pred, y):\n",
    "    return 0.5 * np.sum((y_pred-y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 교차 엔트로피 오차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CEE(cross entropy error) = E = -sum(y * log(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y_pred, y):\n",
    "    delta = 1e-7 # np.log(0) == -inf -> prevent\n",
    "    return -np.sum(y * np.log(y_pred + delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "책 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch(when y is one_hot encoded)\n",
    "def cross_entropy_error1(y_pred, y):\n",
    "    if y_pred.ndim == 1:\n",
    "        y = y.reshape(1, y.size)\n",
    "        y_pred = y.reshape(1, y_pred.size)\n",
    "    \n",
    "    batch_size = y_pred.shape[0]\n",
    "    return -np.sum(y * np.log(y_pred + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch(when y is not one_hot encoded)\n",
    "def cross_entropy_error2(y_pred, y):\n",
    "    if y_pred.ndim == 1:\n",
    "        y = y.reshape(1, y.size)\n",
    "        y_pred = y.reshape(1, y_pred.size)\n",
    "    \n",
    "    batch_size = y_pred.shape[0]\n",
    "    return -np.sum(np.log(y_pred[np.arange(batch_size), y]+ 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5 왜 손실 함수를 설정하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 학습에서는 parameter를 optimize 할 때 미분을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h) / (2 * h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 수치 미분의 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "책 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 편미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "책 참고"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _numerical_gradient_no_batch(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)\n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val        \n",
    "    return grad\n",
    "\n",
    "\n",
    "def numerical_gradient(f, X):\n",
    "    if X.ndim == 1:\n",
    "        return _numerical_gradient_no_batch(f, X)\n",
    "    else:\n",
    "        grad = np.zeros_like(X)\n",
    "        \n",
    "        for idx, x in enumerate(X):\n",
    "            grad[idx] = _numerical_gradient_no_batch(f, x)\n",
    "        \n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def function_2(x):\n",
    "    return np.sum(x ** 2)\n",
    "\n",
    "numerical_gradient(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 경사법(경사 하강법)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x0, x1 = x - eta * numerical_gradient  \n",
    "eta: learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4.2 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    c = np.max(x)\n",
    "    exp_x = np.exp(x-c)\n",
    "    sum_exp_x = np.sum(exp_x-c)\n",
    "    y = exp_x / sum_exp_x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2, 3)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, y):\n",
    "        z = self.predict(x)\n",
    "        y_pred = softmax(z)\n",
    "        loss = cross_entropy_error1(y_pred, y)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.50093784  0.60734283 -0.40662738]\n",
      " [ 0.86203722  1.5465298  -1.42010576]]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-9.999999505838704e-08"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)\n",
    "x = np.array([0.6, 0.9])\n",
    "y_pred = net.predict(x)\n",
    "print(np.argmax(y_pred))\n",
    "y = np.array([0, 0, 1])\n",
    "net.loss(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1단계: 미니배치  \n",
    "-> 훈련 데이터 중 일부를 무작위로 가져온후(확률적 경사 하강법) 그 미니배치의 손실 함수 값을 줄여야함  \n",
    "2단계: 기울기 산출  \n",
    "-> 각 가중치 매개변수의 기울기를 구한다.  \n",
    "3단계: 매개변수 갱신  \n",
    "-> 가중치 매개변수를 갱신한다.  \n",
    "4단계: 반복  \n",
    "-> 적절히 학습될 때 까지 반복"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, ouput_size, weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, ouput_size)\n",
    "        self.params['b2'] = np.zeros(ouput_size)\n",
    "\n",
    "    def predict(self, X):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "        a1 = np.dot(X, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def loss(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "\n",
    "        return cross_entropy_error1(y_pred, y)\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y = np.argmax(y, axis=1)\n",
    "\n",
    "        accuracy = np.sum(y_pred == t) / float(X.shape[0])\n",
    "        return accuracy\n",
    "\n",
    "    def numerical_gradient(self, X, y):\n",
    "        loss_W = lambda W: self.loss(X, y)\n",
    "\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, ouput_size=10)\n",
    "X = np.random.rand(100, 784)\n",
    "y_pred = net.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.random.rand(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[-0.0057976 , -0.00986031,  0.00412719, ...,  0.00393074,\n",
       "         -0.01166395,  0.0075011 ],\n",
       "        [-0.00849637, -0.01447001,  0.00631011, ...,  0.00583378,\n",
       "         -0.01737105,  0.01101892],\n",
       "        [-0.00336681, -0.00565316,  0.00207201, ...,  0.00230151,\n",
       "         -0.00659406,  0.00435532],\n",
       "        ...,\n",
       "        [-0.00610132, -0.01036529,  0.00422813, ...,  0.00419283,\n",
       "         -0.01233546,  0.00785279],\n",
       "        [-0.00476939, -0.00794245,  0.00319993, ...,  0.00322592,\n",
       "         -0.00955559,  0.00603055],\n",
       "        [-0.00935923, -0.0161094 ,  0.00696939, ...,  0.00647335,\n",
       "         -0.01910267,  0.01230543]]),\n",
       " 'b1': array([-0.01123123, -0.01912047,  0.00797039,  0.01853413,  0.01062306,\n",
       "        -0.00817326, -0.02147835, -0.00794657, -0.00855942, -0.02051595,\n",
       "         0.01213878,  0.0256261 , -0.01254031,  0.01082492,  0.01056655,\n",
       "        -0.02082665, -0.0097519 ,  0.01112733, -0.02648476,  0.01835583,\n",
       "        -0.01702786,  0.02168456,  0.00104009,  0.00646827,  0.01240994,\n",
       "         0.01383703, -0.01533297,  0.00150431, -0.00526323, -0.02666308,\n",
       "        -0.01108374, -0.04048029,  0.00130177,  0.01582727, -0.00931715,\n",
       "        -0.00737135, -0.01956364,  0.0016675 ,  0.00580029, -0.00897534,\n",
       "        -0.02273424,  0.01712206, -0.01501746,  0.0114129 , -0.00499706,\n",
       "         0.01488113,  0.00948528, -0.0060574 ,  0.00252928, -0.02565812,\n",
       "         0.03596059, -0.02092661,  0.018575  , -0.02228029, -0.00987997,\n",
       "        -0.00871365, -0.02045397,  0.00264432, -0.02726223,  0.01602824,\n",
       "        -0.000541  , -0.00163716,  0.02349116, -0.01001289, -0.00248996,\n",
       "         0.0112532 , -0.00041319,  0.01368975,  0.00099561, -0.01716931,\n",
       "        -0.0095455 , -0.00499808, -0.01039373,  0.02751959, -0.01583669,\n",
       "        -0.00136024,  0.00143297,  0.00034417, -0.02597051, -0.00682631,\n",
       "        -0.00591003, -0.00990355, -0.0074648 ,  0.04515896, -0.00259291,\n",
       "        -0.01154232, -0.02942535, -0.01705367, -0.02836175,  0.02678722,\n",
       "        -0.00343891,  0.02665426, -0.02580377,  0.00669826,  0.00706874,\n",
       "        -0.01724965, -0.00974745,  0.00774332, -0.02279396,  0.01461791]),\n",
       " 'W2': array([[ 0.0099066 ,  0.03424721, -2.84016385,  0.01032435,  0.02347335,\n",
       "          0.01919888,  0.00797813,  0.02058986,  0.01996105,  0.04726135],\n",
       "        [ 0.01119626,  0.03581098, -3.22739858,  0.01273682,  0.02636114,\n",
       "          0.02059031,  0.0078351 ,  0.0226495 ,  0.02190515,  0.05235322],\n",
       "        [ 0.01053869,  0.03377781, -3.20677468,  0.01107908,  0.02411536,\n",
       "          0.01863271,  0.00659579,  0.01987086,  0.02028983,  0.04784547],\n",
       "        [ 0.0111003 ,  0.03800606, -3.32492423,  0.01244155,  0.02539346,\n",
       "          0.02020984,  0.0082578 ,  0.02339481,  0.02075865,  0.05178494],\n",
       "        [ 0.00889057,  0.03293805, -2.93062305,  0.01078628,  0.02175361,\n",
       "          0.01801528,  0.00741745,  0.02010045,  0.02063107,  0.04607848],\n",
       "        [ 0.01055194,  0.03814374, -3.62403262,  0.012289  ,  0.02623821,\n",
       "          0.02080285,  0.00737812,  0.02324289,  0.02320377,  0.05482955],\n",
       "        [ 0.00952443,  0.03384355, -3.23082017,  0.01097385,  0.02297806,\n",
       "          0.0178093 ,  0.00701507,  0.02025421,  0.01971128,  0.04816781],\n",
       "        [ 0.01122546,  0.03646765, -3.27892098,  0.01260989,  0.02589642,\n",
       "          0.01978533,  0.00712425,  0.02270187,  0.02157338,  0.05137583],\n",
       "        [ 0.00975939,  0.03361987, -3.15331258,  0.01054454,  0.02216732,\n",
       "          0.01872136,  0.00711892,  0.02064441,  0.02021127,  0.04746544],\n",
       "        [ 0.01208322,  0.0413505 , -3.94108033,  0.0136737 ,  0.02816095,\n",
       "          0.02286405,  0.00885357,  0.02458606,  0.02371028,  0.05695129],\n",
       "        [ 0.01284074,  0.0417064 , -3.84785705,  0.01457113,  0.02941699,\n",
       "          0.02237349,  0.00930006,  0.0248666 ,  0.02530697,  0.06007247],\n",
       "        [ 0.00995764,  0.03705661, -3.0039179 ,  0.01063328,  0.02555184,\n",
       "          0.02002184,  0.00787724,  0.02207358,  0.02115441,  0.05034492],\n",
       "        [ 0.00936664,  0.03157544, -2.93420112,  0.0104507 ,  0.02200542,\n",
       "          0.01823098,  0.0076498 ,  0.02018723,  0.01799205,  0.04392431],\n",
       "        [ 0.01136122,  0.03645921, -3.28226318,  0.0122622 ,  0.02583682,\n",
       "          0.01905086,  0.00794864,  0.02196009,  0.02094718,  0.0512518 ],\n",
       "        [ 0.01051422,  0.03018495, -2.92784828,  0.00938517,  0.02159664,\n",
       "          0.01703899,  0.00684982,  0.02052234,  0.01819994,  0.04386142],\n",
       "        [ 0.01117856,  0.03893289, -3.4067603 ,  0.01243064,  0.02693075,\n",
       "          0.02161878,  0.00794545,  0.02383605,  0.02315605,  0.05386934],\n",
       "        [ 0.0102174 ,  0.03543855, -3.32487046,  0.01205174,  0.02434623,\n",
       "          0.01974707,  0.00724853,  0.02080789,  0.02090993,  0.05146712],\n",
       "        [ 0.00976341,  0.03528264, -3.35291735,  0.01224462,  0.0246052 ,\n",
       "          0.02029337,  0.00769942,  0.02152146,  0.02129548,  0.04855466],\n",
       "        [ 0.00969942,  0.03133924, -2.81193963,  0.009953  ,  0.02153122,\n",
       "          0.01646493,  0.0063277 ,  0.01841152,  0.01845277,  0.0434794 ],\n",
       "        [ 0.00952638,  0.03326399, -3.11205854,  0.01103571,  0.02352947,\n",
       "          0.01894353,  0.00613256,  0.02166675,  0.02032152,  0.0472832 ],\n",
       "        [ 0.0099223 ,  0.03370814, -3.1319784 ,  0.01111736,  0.02376883,\n",
       "          0.01860318,  0.00707368,  0.02043541,  0.02054104,  0.04686848],\n",
       "        [ 0.00970197,  0.03384995, -2.8653212 ,  0.01204928,  0.02361662,\n",
       "          0.0193052 ,  0.00695504,  0.02095571,  0.01955144,  0.04712252],\n",
       "        [ 0.01040505,  0.03696674, -3.05830904,  0.01345826,  0.02550269,\n",
       "          0.02007841,  0.0077456 ,  0.02299854,  0.02172996,  0.05140121],\n",
       "        [ 0.00963541,  0.03592369, -3.43347178,  0.01218786,  0.02465534,\n",
       "          0.02065956,  0.00854363,  0.02245424,  0.02143414,  0.05299626],\n",
       "        [ 0.01085467,  0.03604161, -3.11156914,  0.01152165,  0.02470989,\n",
       "          0.01942504,  0.0075392 ,  0.02018739,  0.02083294,  0.04926299],\n",
       "        [ 0.01089859,  0.03706533, -3.19142822,  0.01142348,  0.02497565,\n",
       "          0.01934889,  0.00825948,  0.02318348,  0.02240339,  0.05217629],\n",
       "        [ 0.01073691,  0.03611237, -3.45348785,  0.01205242,  0.02480752,\n",
       "          0.02079829,  0.00927755,  0.02273957,  0.02166889,  0.05208215],\n",
       "        [ 0.01050902,  0.03644497, -2.99867779,  0.01231566,  0.02451413,\n",
       "          0.0191819 ,  0.00852246,  0.0224294 ,  0.02064993,  0.05082016],\n",
       "        [ 0.01073875,  0.03574994, -3.29694601,  0.01138424,  0.02365293,\n",
       "          0.01951204,  0.00732919,  0.02085643,  0.021846  ,  0.04974626],\n",
       "        [ 0.00892366,  0.03194922, -2.81525189,  0.01021494,  0.02153323,\n",
       "          0.01575161,  0.00649735,  0.01884746,  0.01829679,  0.04331802],\n",
       "        [ 0.01072331,  0.03451776, -3.11940771,  0.01134726,  0.02387398,\n",
       "          0.01912652,  0.00635279,  0.02187818,  0.02059714,  0.04941071],\n",
       "        [ 0.01215508,  0.03749331, -3.33216052,  0.01291871,  0.02632258,\n",
       "          0.01949594,  0.00782317,  0.02385213,  0.02233178,  0.05389596],\n",
       "        [ 0.00936907,  0.03085601, -2.87172719,  0.01072107,  0.02226041,\n",
       "          0.01704402,  0.00627345,  0.01926519,  0.01802199,  0.04479018],\n",
       "        [ 0.00997353,  0.03659361, -3.35067737,  0.011885  ,  0.02573768,\n",
       "          0.01982107,  0.0069739 ,  0.02119916,  0.02167192,  0.05170584],\n",
       "        [ 0.01004825,  0.03359181, -3.11664328,  0.01171365,  0.02244287,\n",
       "          0.01933681,  0.00771616,  0.0200042 ,  0.02005278,  0.04691979],\n",
       "        [ 0.01015027,  0.03433365, -2.81574837,  0.01135442,  0.02468613,\n",
       "          0.01875552,  0.007471  ,  0.02146308,  0.01953656,  0.04765453],\n",
       "        [ 0.01068427,  0.03334003, -3.21772541,  0.01158979,  0.02350511,\n",
       "          0.01798105,  0.00598696,  0.02017564,  0.02046311,  0.0475123 ],\n",
       "        [ 0.00922427,  0.03381622, -3.00444508,  0.01033776,  0.02299174,\n",
       "          0.01731809,  0.00857202,  0.02077938,  0.02046659,  0.04760845],\n",
       "        [ 0.01087362,  0.03593025, -3.19263334,  0.0115522 ,  0.02369377,\n",
       "          0.01985487,  0.00707609,  0.02122301,  0.01974993,  0.04870111],\n",
       "        [ 0.01010423,  0.03462825, -3.04888903,  0.01144857,  0.02401605,\n",
       "          0.01995056,  0.00741299,  0.0222321 ,  0.01992236,  0.04881152],\n",
       "        [ 0.00963343,  0.03545895, -3.20260238,  0.01149773,  0.02449443,\n",
       "          0.01930109,  0.00802316,  0.02145718,  0.0206455 ,  0.04923001],\n",
       "        [ 0.01024798,  0.03739869, -3.1228356 ,  0.01257691,  0.02453056,\n",
       "          0.01882074,  0.00798017,  0.02176388,  0.02063072,  0.05078344],\n",
       "        [ 0.00878481,  0.03360957, -3.06083643,  0.0112726 ,  0.02441851,\n",
       "          0.01810018,  0.00734845,  0.01957408,  0.01832734,  0.04503179],\n",
       "        [ 0.00834345,  0.03503031, -2.97940416,  0.01173782,  0.02374568,\n",
       "          0.0180281 ,  0.00718176,  0.01998512,  0.01877776,  0.0465066 ],\n",
       "        [ 0.01158465,  0.03993507, -3.46081025,  0.01276789,  0.0275928 ,\n",
       "          0.02099917,  0.00648339,  0.02351064,  0.02253311,  0.05363926],\n",
       "        [ 0.01193254,  0.03843387, -3.29037429,  0.01267479,  0.02662381,\n",
       "          0.02079965,  0.00785063,  0.02357719,  0.02223444,  0.05186149],\n",
       "        [ 0.010293  ,  0.0354282 , -3.09067056,  0.01106797,  0.02481453,\n",
       "          0.01867529,  0.00707164,  0.02093657,  0.02085167,  0.04935979],\n",
       "        [ 0.00927245,  0.03118457, -2.92049597,  0.0100071 ,  0.02257585,\n",
       "          0.01754267,  0.0069252 ,  0.02034877,  0.01935936,  0.04415663],\n",
       "        [ 0.01180746,  0.03762921, -3.56893207,  0.01264221,  0.02528145,\n",
       "          0.02155545,  0.00743016,  0.02268567,  0.02334353,  0.05270461],\n",
       "        [ 0.00924345,  0.03298865, -3.14938549,  0.01110145,  0.02224304,\n",
       "          0.01837462,  0.00758062,  0.01967633,  0.01823835,  0.04627901],\n",
       "        [ 0.01016407,  0.03559829, -3.29135262,  0.01082222,  0.02480286,\n",
       "          0.01895279,  0.00728575,  0.02217994,  0.02185015,  0.0503093 ],\n",
       "        [ 0.00860722,  0.03783446, -3.37352884,  0.0124207 ,  0.02597479,\n",
       "          0.02040219,  0.00801335,  0.02352359,  0.02290871,  0.05228274],\n",
       "        [ 0.00953622,  0.03731465, -3.27569297,  0.01307382,  0.02526313,\n",
       "          0.02107644,  0.00879512,  0.02255671,  0.02176218,  0.05215652],\n",
       "        [ 0.00940233,  0.03596245, -3.50948397,  0.01175502,  0.02516985,\n",
       "          0.01856203,  0.0073516 ,  0.0202459 ,  0.02121052,  0.04935869],\n",
       "        [ 0.01058653,  0.03688039, -3.35450559,  0.01235472,  0.02661646,\n",
       "          0.01950189,  0.00751101,  0.02211463,  0.02213274,  0.05101381],\n",
       "        [ 0.01019713,  0.03613522, -3.2802214 ,  0.01118871,  0.02448796,\n",
       "          0.01938931,  0.0059424 ,  0.02233501,  0.02119457,  0.05015343],\n",
       "        [ 0.01034024,  0.03706484, -3.39848622,  0.01208534,  0.02593668,\n",
       "          0.02005849,  0.00782473,  0.02260265,  0.02107056,  0.0506823 ],\n",
       "        [ 0.01013566,  0.03747866, -3.25272572,  0.01173859,  0.02595814,\n",
       "          0.02045217,  0.00810453,  0.02303507,  0.02232166,  0.05141904],\n",
       "        [ 0.01025382,  0.03469615, -3.34682801,  0.01203382,  0.02334817,\n",
       "          0.01943469,  0.00765401,  0.0207095 ,  0.01991936,  0.04818489],\n",
       "        [ 0.00892477,  0.03219508, -2.73762759,  0.00987052,  0.02201054,\n",
       "          0.01589271,  0.00679917,  0.01975904,  0.01867579,  0.04393282],\n",
       "        [ 0.00975136,  0.03314653, -2.79602925,  0.01159381,  0.02180164,\n",
       "          0.01873987,  0.00653067,  0.01979626,  0.0187424 ,  0.04626849],\n",
       "        [ 0.01059414,  0.03465379, -3.26954696,  0.01175011,  0.02443466,\n",
       "          0.01873515,  0.00779676,  0.02137677,  0.02031949,  0.04938826],\n",
       "        [ 0.01028739,  0.03845011, -3.4593972 ,  0.01282094,  0.02579652,\n",
       "          0.02029057,  0.00808294,  0.02240508,  0.0215757 ,  0.05269668],\n",
       "        [ 0.0120831 ,  0.03891939, -3.40839695,  0.01328245,  0.0272905 ,\n",
       "          0.02048616,  0.00770947,  0.0226542 ,  0.02139531,  0.05326865],\n",
       "        [ 0.01027785,  0.03597438, -3.30439983,  0.01192224,  0.02464541,\n",
       "          0.02017812,  0.0084408 ,  0.02064581,  0.02121798,  0.04924962],\n",
       "        [ 0.01028845,  0.03835268, -3.43721861,  0.01301453,  0.02649744,\n",
       "          0.02062261,  0.00731942,  0.02317349,  0.02164862,  0.05302774],\n",
       "        [ 0.00997803,  0.03119266, -2.96919146,  0.00991761,  0.0224984 ,\n",
       "          0.01623452,  0.00748534,  0.02079616,  0.01857965,  0.04421512],\n",
       "        [ 0.01041286,  0.03647893, -3.17834043,  0.0124883 ,  0.02470446,\n",
       "          0.01943428,  0.00715162,  0.02236025,  0.02101209,  0.05010689],\n",
       "        [ 0.01023899,  0.03791766, -3.3678144 ,  0.01137488,  0.02653822,\n",
       "          0.01986538,  0.00840423,  0.02258749,  0.02244035,  0.05248193],\n",
       "        [ 0.00979522,  0.03489124, -3.0273547 ,  0.01074862,  0.02335719,\n",
       "          0.01906192,  0.00874405,  0.02169931,  0.01968295,  0.04750012],\n",
       "        [ 0.01108007,  0.03960495, -3.48557539,  0.0122545 ,  0.02693753,\n",
       "          0.02046146,  0.00822634,  0.02239553,  0.02180108,  0.05369909],\n",
       "        [ 0.00993405,  0.03711208, -3.21275467,  0.01158029,  0.02495168,\n",
       "          0.01901881,  0.00912714,  0.021693  ,  0.02139244,  0.05235198],\n",
       "        [ 0.01020069,  0.03349584, -3.17827322,  0.01012948,  0.02454466,\n",
       "          0.01808352,  0.00696044,  0.02061312,  0.02035016,  0.04796752],\n",
       "        [ 0.01033782,  0.03268744, -3.02239952,  0.01014956,  0.0225701 ,\n",
       "          0.01675665,  0.00648708,  0.01917009,  0.01874701,  0.04467857],\n",
       "        [ 0.01052873,  0.03464853, -3.15214083,  0.01157004,  0.02438568,\n",
       "          0.01844607,  0.00729715,  0.02108761,  0.0200888 ,  0.04751092],\n",
       "        [ 0.00998098,  0.03319056, -2.9458074 ,  0.0109518 ,  0.02262561,\n",
       "          0.01741507,  0.00747737,  0.01949561,  0.01832006,  0.04497168],\n",
       "        [ 0.00884241,  0.03111735, -3.05592989,  0.009682  ,  0.0210695 ,\n",
       "          0.01767318,  0.00789363,  0.01901789,  0.01892814,  0.04376935],\n",
       "        [ 0.01128122,  0.03579237, -3.08151671,  0.01168135,  0.02368676,\n",
       "          0.01935527,  0.00740435,  0.02167094,  0.01966255,  0.04839281],\n",
       "        [ 0.01011058,  0.03268302, -3.25885821,  0.01075021,  0.02365736,\n",
       "          0.01876576,  0.00725401,  0.02117035,  0.02003534,  0.04583949],\n",
       "        [ 0.00913849,  0.03473825, -2.8433434 ,  0.0108589 ,  0.02313032,\n",
       "          0.01775425,  0.00741996,  0.02019856,  0.01902198,  0.0459041 ],\n",
       "        [ 0.01067284,  0.03903044, -3.36979629,  0.01351012,  0.02564201,\n",
       "          0.01922357,  0.00832734,  0.0228195 ,  0.02265127,  0.05378921],\n",
       "        [ 0.0108753 ,  0.03894167, -3.55503653,  0.01164754,  0.02494779,\n",
       "          0.01947338,  0.00805491,  0.02266027,  0.02268243,  0.05333826],\n",
       "        [ 0.00919864,  0.03299184, -2.8992972 ,  0.01053728,  0.02263353,\n",
       "          0.01846912,  0.00644458,  0.0205018 ,  0.02013047,  0.04630018],\n",
       "        [ 0.0116401 ,  0.04129189, -3.42447038,  0.01369518,  0.02838001,\n",
       "          0.02132988,  0.00846396,  0.02432838,  0.0232199 ,  0.05712525],\n",
       "        [ 0.01017904,  0.03418475, -2.9181336 ,  0.01087513,  0.0243908 ,\n",
       "          0.01746088,  0.0061602 ,  0.02052404,  0.02008302,  0.04638999],\n",
       "        [ 0.00947028,  0.03420958, -3.27983929,  0.01133361,  0.02308107,\n",
       "          0.0185312 ,  0.00682736,  0.0197192 ,  0.01980041,  0.04782795],\n",
       "        [ 0.01188968,  0.04041535, -3.66639467,  0.01303541,  0.02670701,\n",
       "          0.02165536,  0.00962721,  0.02610902,  0.02432011,  0.05608761],\n",
       "        [ 0.01053108,  0.03440243, -3.01754096,  0.01162266,  0.02317639,\n",
       "          0.01877726,  0.00793776,  0.02156888,  0.02026499,  0.04859812],\n",
       "        [ 0.01050563,  0.03486165, -3.23640898,  0.0108513 ,  0.02363931,\n",
       "          0.01941506,  0.00839993,  0.02208842,  0.02088995,  0.04958319],\n",
       "        [ 0.00958552,  0.03263752, -2.93224283,  0.01071542,  0.02261754,\n",
       "          0.01766765,  0.00605522,  0.01926156,  0.01880956,  0.04638887],\n",
       "        [ 0.01094559,  0.03882345, -3.27850012,  0.01244206,  0.02624162,\n",
       "          0.02064797,  0.00893762,  0.02490484,  0.02305099,  0.05288103],\n",
       "        [ 0.00967179,  0.03634918, -3.31881614,  0.01206588,  0.02533705,\n",
       "          0.01944906,  0.00708788,  0.02231937,  0.02101218,  0.05021032],\n",
       "        [ 0.01075811,  0.0373597 , -3.37846452,  0.01329474,  0.02544862,\n",
       "          0.02060119,  0.00766217,  0.02350766,  0.02169375,  0.05194817],\n",
       "        [ 0.00926815,  0.03248592, -3.00959632,  0.01127366,  0.02364194,\n",
       "          0.01823822,  0.00677338,  0.0198561 ,  0.01948409,  0.04547959],\n",
       "        [ 0.0106212 ,  0.03791742, -3.33509862,  0.01143509,  0.02572959,\n",
       "          0.01980067,  0.00689492,  0.02196814,  0.02085322,  0.05206223],\n",
       "        [ 0.00984625,  0.03338248, -3.26648893,  0.01172017,  0.02326658,\n",
       "          0.01727846,  0.00719087,  0.02105024,  0.01965502,  0.04651166],\n",
       "        [ 0.01018861,  0.03833184, -3.41545654,  0.0124417 ,  0.02649772,\n",
       "          0.02008582,  0.00759676,  0.02207191,  0.02208807,  0.05200754],\n",
       "        [ 0.00783427,  0.03016943, -2.8144012 ,  0.00994493,  0.0209959 ,\n",
       "          0.01691513,  0.00652486,  0.01733052,  0.01744687,  0.04076699],\n",
       "        [ 0.00725475,  0.03061954, -2.97097941,  0.01033063,  0.02173443,\n",
       "          0.01549187,  0.00585418,  0.0170813 ,  0.01652577,  0.04222236],\n",
       "        [ 0.0101065 ,  0.03493705, -3.39477852,  0.01262472,  0.02500941,\n",
       "          0.01926028,  0.00821695,  0.02190401,  0.02047463,  0.04952635]]),\n",
       " 'b2': array([ 0.02021493,  0.07037712, -6.32653327,  0.0227858 ,  0.04816946,\n",
       "         0.03781591,  0.01500347,  0.0422661 ,  0.04108357,  0.09768083])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
